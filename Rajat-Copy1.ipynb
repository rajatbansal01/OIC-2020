{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from csv import DictWriter\n",
    "import sys\n",
    "import local_utils\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "#try:\n",
    "from PIL import Image\n",
    "#except ImportError:\n",
    "#     import Image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "from local_utils import detect_lp\n",
    "from os.path import splitext,basename\n",
    "from keras.models import model_from_json\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "import numpy as np\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['date', 'v_number', 'plate_path' , 'face_path']) #make a pandas datafrmae for csv\n",
    "df.to_csv('data_new.csv') #save the csv with column names\n",
    "try:\n",
    "    os.mkdir(\"faces\")\n",
    "except FileExistsError:\n",
    "    print(\"already exists\")\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(\"plates\")\n",
    "except FileExistsError:\n",
    "    print(\"already exists\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model successfully...\n"
     ]
    }
   ],
   "source": [
    "#laod model from json file\n",
    "def load_model(path):\n",
    "    try:\n",
    "        path = splitext(path)[0]\n",
    "        with open('%s.json' % path, 'r') as json_file:\n",
    "            model_json = json_file.read()\n",
    "        model = model_from_json(model_json, custom_objects={})\n",
    "        model.load_weights('%s.h5' % path)\n",
    "        print(\"Loading model successfully...\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "#processing image.        \n",
    "def preprocess_image(img,resize=False):\n",
    "    #img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (224,224))\n",
    "    return img\n",
    "\n",
    "#get plate from frame \n",
    "# LpImg may contain more than one plate image in list\n",
    "def get_plate(img, Dmax=608, Dmin=256):\n",
    "    vehicle = preprocess_image(img)\n",
    "    ratio = float(max(vehicle.shape[:2])) / min(vehicle.shape[:2])\n",
    "    side = int(ratio * Dmin)\n",
    "    bound_dim = min(side, Dmax)\n",
    "    _ , LpImg, _, cor = detect_lp(wpod_net, vehicle, bound_dim, lp_threshold=0.5)\n",
    "    return(vehicle, LpImg, cor)\n",
    "\n",
    "# return image to  be passed for OCR, it return a list of different images\n",
    "def image_for_ocr(LpImg):\n",
    "    if (len(LpImg)): #check if there is at least one license image\n",
    "        # Scales, calculates absolute values, and converts the result to 8-bit.\n",
    "        plate_image = cv2.convertScaleAbs(LpImg[0], alpha=(255.0))\n",
    "        #plt.imshow(plate_image)\n",
    "        #plt.title(\"Plate image\")\n",
    "        # convert to grayscale and blur the image\n",
    "        gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
    "        #blur = cv2.GaussianBlur(gray,(7,7),0)\n",
    "        \n",
    "        # Applied inversed thresh_binary \n",
    "        binary = cv2.threshold(gray, 180, 255,\n",
    "                            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "        binary= cv2.bitwise_not(binary)\n",
    "        kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)\n",
    "    return([plate_image,gray,binary,kernel3,thre_mor])\n",
    "\n",
    "\n",
    "#finally reurns a string of registration number and a image of plate\n",
    "def find_num(img):\n",
    "    #img = cv2.imread(path)\n",
    "    LpImg =0\n",
    "    try:\n",
    "        vehicle, LpImg,cor = get_plate(img)\n",
    "    except AssertionError:\n",
    "        pass\n",
    "    s=[]\n",
    "    if LpImg:\n",
    "        ocr_image=image_for_ocr(LpImg)[0]\n",
    "        img_tosave = image_for_ocr(LpImg)[2]\n",
    "        number= pytesseract.image_to_string(ocr_image,lang=\"eng\")\n",
    "        for i in number:\n",
    "            if i.isalnum() and (not i.islower()):\n",
    "                s.append(i)\n",
    "        return(\"\".join(s),img_tosave)\n",
    "    else:\n",
    "        return(0,0)\n",
    "    \n",
    "# draw box on plate in image if found\n",
    "def draw_box(image_path, cor, thickness=3):\n",
    "    pts=[]  \n",
    "    x_coordinates=cor[0][0]\n",
    "    y_coordinates=cor[0][1]\n",
    "    # store the top-left, top-right, bottom-left, bottom-right \n",
    "    # of the plate license respectively\n",
    "    for i in range(4):\n",
    "        pts.append([int(x_coordinates[i]),int(y_coordinates[i])])\n",
    "    \n",
    "    pts = np.array(pts, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    vehicle_image = preprocess_image(image_path)\n",
    "    \n",
    "    cv2.polylines(vehicle_image,[pts],True,(0,255,0),thickness)\n",
    "    return vehicle_image\n",
    "\n",
    "#detect face from a image (ndarray) and return face if found otherwise the same frame.\n",
    "def detect(frame):\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) #changing RGB to gray for better classification\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is not ():\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame ,(x-w//2,y-h//2), (x+2*w ,y+2*h),(255,0,0),2)\n",
    "            img = frame[y-h//2:y+2*h , x-w//2:x+2*w]\n",
    "        return(img)\n",
    "    else:\n",
    "        return(frame)\n",
    "\n",
    "wpod_net_path = \"wpod-net.json\"\n",
    "wpod_net = load_model(wpod_net_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number plate csv updater\n",
    "def csv_updater(v_number):    \n",
    "        with open('data_new.csv','a', newline = '') as f:\n",
    "            csv_file = DictWriter(f, fieldnames = [\"date\",\"v_number\"])\n",
    "            csv_file.writerows([\n",
    "            {'date': [time.asctime( time.localtime(time.time()) )], 'v_number': v_number}\n",
    "                ])\n",
    "        f.close()\n",
    "        \n",
    "\n",
    "# plate path updater        \n",
    "def plate_updater():    \n",
    "        with open('data_new.csv','a', newline = '') as f:\n",
    "            csv_file = DictWriter(f, fieldnames = [\"date\",\"v_number\"])\n",
    "            csv_file.writerows([\n",
    "            {'date': [time.asctime( time.localtime(time.time()) )], 'v_number': v_number}\n",
    "                ])\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "#find a most common string from list\n",
    "def most_frequent(List): \n",
    "    dict = {} \n",
    "    count, itm = 0, '' \n",
    "    for item in reversed(List): \n",
    "        dict[item] = dict.get(item, 0) + 1\n",
    "        if dict[item] >= count : \n",
    "            count, itm = dict[item], item \n",
    "    return(itm)\n",
    "# erode image \n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    # Now we erode\n",
    "    erosion = cv2.erode(image, kernel, iterations = 1)\n",
    "    return(erosion)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#save the image of face name is the current time date\n",
    "def save_face(img):\n",
    "    name = time.asctime()[4:16]\n",
    "    name = name.replace(\":\", \"_\")\n",
    "    cv2.imwrite(\"faces/\"+name+\".jpg\" , img )\n",
    "    \n",
    "# save the image of plate with the name as number \n",
    "def save_plate(image,number):\n",
    "    cv2.imwrite(\"plates/\"+number+ \".jpg\" , image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR41J1677\n",
      "HR41J1677\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-34dfdad1d5d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap_plate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mnumber\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplate_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mplate_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplate_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#cv2.imshow(\"plate\",plate_img) #code to be removed before deployment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-4e0b30b55fcd>\u001b[0m in \u001b[0;36mfind_num\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mLpImg\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mvehicle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLpImg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_plate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-4e0b30b55fcd>\u001b[0m in \u001b[0;36mget_plate\u001b[1;34m(img, Dmax, Dmin)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mside\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mDmin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mbound_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mLpImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_lp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwpod_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvehicle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbound_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlp_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLpImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Machine Learning\\github\\OIC-2020\\Rajat\\local_utils.py\u001b[0m in \u001b[0;36mdetect_lp\u001b[1;34m(model, I, max_dim, lp_threshold)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIresized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m     \u001b[0mYr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m     \u001b[0mYr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;31m#print(Yr.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mD:\\programs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\programs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap_plate = cv2.VideoCapture(\"uiet_test.mp4\") #path to video\n",
    "num=[]\n",
    "while cap_plate.isOpened():\n",
    "    #time.sleep(0.5)\n",
    "    ret,frame = cap_plate.read()\n",
    "    if ret:\n",
    "        number,plate_img = find_num(frame)\n",
    "        plate_img = erode(plate_img)\n",
    "        #cv2.imshow(\"plate\",plate_img) #code to be removed before deployment\n",
    "        if number:\n",
    "            num.append(number)\n",
    "        else:\n",
    "            continue\n",
    "        #if num[0] != num[len(num)-1] and len(num)>1:\n",
    "        if len(num)>30:\n",
    "            n=most_frequent(num)\n",
    "            csv_updater(n)\n",
    "            save_plate(plate_img,n)\n",
    "            cap_face = cv2.VideoCapture(0)\n",
    "            ret,face_frame = cap_face.read()\n",
    "            if ret:\n",
    "                face = detect(face_frame)\n",
    "                save_face(face)\n",
    "                cap_face.release()\n",
    "            else:\n",
    "                pass\n",
    "            print(n)\n",
    "            num = []\n",
    "        else:\n",
    "            continue\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  #13 is enter key\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap_plate.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_plate = cv2.VideoCapture(\"uiet_test.mp4\")\n",
    "num=[]\n",
    "while cap_plate.isOpened():\n",
    "    #time.sleep(0.05)\n",
    "    ret,frame = cap_plate.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        try:\n",
    "            vehicle, LpImg,cor = get_plate(frame)\n",
    "            #plate = draw_box(frame,cor)\n",
    "            plate = image_for_ocr(LpImg)[2]\n",
    "        except AssertionError:\n",
    "            plate = frame\n",
    "        cv2.imshow(\"plate\",plate)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  #13 is enter key\n",
    "            break        \n",
    "    else:\n",
    "        break\n",
    "cap_plate.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_face = cv2.VideoCapture(0)\n",
    "while cap_face.isOpened():\n",
    "    #time.sleep(0.2)\n",
    "    ret,frame = cap_face.read()\n",
    "    if ret:\n",
    "        face_image = detect(frame)\n",
    "        cv2.imshow(\"video\" , face_image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # press enter and \"q\" key to close the window\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap_face.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"test.mp4\") #path to video\n",
    "# num=[]\n",
    "# while cap.isOpened():\n",
    "#     time.sleep(1)\n",
    "#     ret,frame = cap.read()\n",
    "#     if ret:\n",
    "#         gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "#         number = find_num(gray)\n",
    "#         if number:\n",
    "#             num.append(number)\n",
    "#         else:\n",
    "#             continue\n",
    "#         if num[0] != num[len(num)-1] and len(num)>1:\n",
    "#             print(num)\n",
    "#             csv_updater(num[0])\n",
    "#             num = []\n",
    "#         else:\n",
    "#             continue\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):  #13 is enter key\n",
    "#             break\n",
    "#     else:\n",
    "#         break\n",
    "# cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_plate = cv2.VideoCapture(0) #path to video\n",
    "num=[]\n",
    "while cap_plate.isOpened():\n",
    "    time.sleep(0.05)\n",
    "    ret,frame = cap_plate.read()\n",
    "    if ret:\n",
    "        number,plate_img = find_num(frame)\n",
    "        plate_img = erode(plate_img)\n",
    "        if number:\n",
    "            num.append(number)\n",
    "        else:\n",
    "            continue\n",
    "        #if num[0] != num[len(num)-1] and len(num)>1:\n",
    "        if len(num)>20:\n",
    "            n=most_frequent(num)\n",
    "            csv_updater(n)\n",
    "            save_plate(plate_img,n)\n",
    "            cap_face = cv2.VideoCapture()\n",
    "            ret,face_frame = cap_face.read()\n",
    "            if ret:\n",
    "                face = detect(face_frame)\n",
    "                save_face(face)\n",
    "            else:\n",
    "                pass\n",
    "            print(n)\n",
    "            num = []\n",
    "        else:\n",
    "            continue\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  #13 is enter key\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_updater(v_number):\n",
    "    name = time.asctime()[4:16]\n",
    "    name = name.replace(\":\", \"_\")\n",
    "    with open('data_new.csv','a', newline = '') as f:\n",
    "        csv_file = DictWriter(f, fieldnames = [\"date\",\"v_number\",'plate_path','face_path'])\n",
    "        csv_file.writerows([\n",
    "        {'date': [time.asctime( time.localtime(time.time()) )], 'v_number': v_number,\n",
    "         'plate_path':\"plates/\"+v_number+ \".jpg\",'face_path':\"faces/\"+name+\".jpg\"}\n",
    "            ])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
